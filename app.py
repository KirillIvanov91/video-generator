
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from diffusers.pipelines.pipeline_utils import DiffusionPipeline
import torch, uuid
from diffusers.pipelines.text_to_video_synthesis.pipeline_text_to_video_synth import TextToVideoSDPipeline
from torchvision.io import write_video
from pathlib import Path

if torch.cuda.is_available():
    device_name = torch.cuda.get_device_name(0)
    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
    print(f"GPU: {device_name}, VRAM: {vram_gb:.2f} GB")
else:
    print("‚ö†Ô∏è GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω ‚Äî –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU")

app = FastAPI()

output_dir = Path("output")
output_dir.mkdir(exist_ok=True)


print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –º–æ–¥–µ–ª—å...")

try:

    device = "cuda" if torch.cuda.is_available() else "cpu"
    dtype = torch.float16 if torch.cuda.is_available() else torch.float32

    pipe = TextToVideoSDPipeline.from_pretrained(
    "cerspense/zeroscope_v2_XL",
        torch_dtype=torch.float16
    ).to(device)

    

    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
    pipe.enable_model_cpu_offload()
    
    if torch.cuda.is_available() and vram_gb >= 6:
        try:
            pipe.enable_xformers_memory_efficient_attention()
            print("‚úÖ Memory-efficient attention –≤–∫–ª—é—á–µ–Ω")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤–∫–ª—é—á–∏—Ç—å xFormers: {e}")
    else:
        print("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–∞–ª–æ VRAM ‚Äî xFormers –Ω–µ –≤–∫–ª—é—á–µ–Ω")

    print("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
except Exception as exc:
    raise RuntimeError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {exc}")



class VideoRequest(BaseModel):
    prompt: str




@app.post("/generate")
async def generate(req: VideoRequest):
    try:
        
        print(f"üé¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è: {req.prompt}")
            
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ (T, H, W, C)
        video_tensor = pipe(req.prompt, num_inference_steps=30).videos[0]

        # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–µ–π (T, C, H, W) –¥–ª—è torchvision
        video_tensor = video_tensor.permute(0, 3, 1, 2)

        filename = f"{uuid.uuid4().hex}.mp4"
        output_path = output_dir / filename

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º FPS
        write_video(str(output_path), video_tensor, fps=8)
        print(f"‚úÖ –í–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
        
        return {"video_path": str(output_path)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ó–∞–ø—Ä–æ—Å –ø–æ—Å—Ç—É–ø–∏–ª, –Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ –Ω–∞—á–∞–ª–∞—Å—å: {str(e)}")
    
    
@app.get("/")
async def read_root():
    return {"message": "–°–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –∑–∞–ø—É—â–µ–Ω! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç /generate."}





#docker run --gpus all -p 8080:8080 -v ${PWD}:/app zeroscope-server
